# üöÄ Kolibri AI ‚Äî –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

## ‚ö° 60 —Å–µ–∫—É–Ω–¥ –¥–ª—è –Ω–∞—á–∞–ª–∞

### –®–∞–≥ 1: –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
```bash
cd /Users/kolibri/Downloads/os-main\ 8
source .chatvenv/bin/activate
```

### –®–∞–≥ 2: –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä
```bash
uvicorn backend.service.main:app --reload
# –°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ http://localhost:8000
```

### –®–∞–≥ 3: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ AI

**Python**:
```python
import asyncio
from backend.service.ai_core import KolibriAICore

async def main():
    ai = KolibriAICore(secret_key="test-key")
    decision = await ai.reason("What is AI?")
    print(f"Response: {decision.response}")
    print(f"Verified: {decision.verify_signature('test-key')}")

asyncio.run(main())
```

**Curl**:
```bash
curl -X POST http://localhost:8000/api/v1/ai/reason \
  -H "Content-Type: application/json" \
  -d '{"prompt": "–ß—Ç–æ —Ç–∞–∫–æ–µ –ò–ò?"}'
```

**Python-REPL**:
```python
from backend.service.ai_core import KolibriAICore
import asyncio

ai = KolibriAICore(secret_key="dev")
result = asyncio.run(ai.reason("2+2=?"))
print(result.response)  # "The answer is 4"
```

---

## üìä –û—Å–Ω–æ–≤–Ω—ã–µ API endpoints

| –ú–µ—Ç–æ–¥ | URL | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|-------|-----|-----------|
| POST | `/api/v1/ai/reason` | –ï–¥–∏–Ω–∏—á–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ |
| POST | `/api/v1/ai/reason/batch` | –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (100 max) |
| GET | `/api/v1/ai/stats` | –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã |

---

## üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –í—Å–µ AI —Ç–µ—Å—Ç—ã
pytest tests/test_ai_core.py tests/test_kolibri_api_integration.py -v

# –û–¥–∏–Ω —Ç–µ—Å—Ç
pytest tests/test_ai_core.py::TestKolibriAICore::test_reason_symbolic_only -v

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º
pytest --cov=backend.service.ai_core tests/test_ai_core.py
```

---

## üìö –í–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã

| –§–∞–π–ª | –û–ø–∏—Å–∞–Ω–∏–µ |
|------|----------|
| `backend/service/ai_core.py` | **–Ø–¥—Ä–æ AI (–≥–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª)** |
| `backend/service/routes/inference.py` | API endpoints |
| `tests/test_ai_core.py` | Unit —Ç–µ—Å—Ç—ã (–ø—Ä–∏–º–µ—Ä—ã) |
| `KOLIBRI_AI_IMPLEMENTATION.md` | –ü–æ–ª–Ω–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è |
| `KOLIBRI_AI_FINAL_STATUS.md` | –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞ |

---

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### Environment –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ

```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ
export KOLIBRI_SECRET_KEY="my-secret"
export ENABLE_LLM="true"           # –í–∫–ª—é—á–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π LLM
export LLM_ENDPOINT="http://localhost:11434"
export OFFLINE_MODE="true"         # –†–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞

# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
export ENERGY_BUDGET="0.1"         # J (–¥–∂–æ—É–ª–∏)
export LATENCY_SLO="500"           # –º—Å
```

### Python –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
from backend.service.ai_core import KolibriAICore, InferenceMode

ai = KolibriAICore(
    secret_key="production-key",
    enable_llm=True,              # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    llm_endpoint="http://localhost:11434",
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
decision = await ai.reason("Your query here")
print(decision.response)
print(f"Energy: {decision.energy_cost_j}J")
print(f"Verified: {decision.verify_signature('production-key')}")
```

---

## üìà –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°–∏–º–≤–æ–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ (Fast)
```python
query = "What is 2+2?"
decision = await ai.reason(query)
# Mode: SCRIPT, Energy: 0.03J, Time: ~4ms, Confidence: 99%
```

### –ì–∏–±—Ä–∏–¥–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ (Smart)
```python
query = "Explain photosynthesis"
decision = await ai.reason(query)
# Mode: HYBRID, Energy: 0.08J, Time: ~38ms, Confidence: 94%
```

### –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
```python
queries = ["Q1", "Q2", "Q3", "Q4", "Q5"]
decisions = await ai.batch_reason(queries)
# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, –º–∞–∫—Å 100 –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
```

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
```python
stats = ai.get_stats()
print(f"Total queries: {stats['total_queries']}")
print(f"Total energy: {stats['total_energy_j']}J")
print(f"Avg per query: {stats['avg_energy_per_query_j']}J")
```

---

## üîê –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è

```python
# –ü–æ–ª—É—á–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ
decision = await ai.reason("query")

# –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–ø–∏—Å—å
is_valid = decision.verify_signature("my-secret-key")
if is_valid:
    print("‚úì –†–µ—à–µ–Ω–∏–µ –ø–æ–¥–ª–∏–Ω–Ω–æ–µ")
else:
    print("‚úó –†–µ—à–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–¥–¥–µ–ª–∞–Ω–æ")
```

---

## üêõ –û—Ç–ª–∞–¥–∫–∞

### –í–∫–ª—é—á–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("kolibri.ai.core")
logger.setLevel(logging.DEBUG)
```

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã
```bash
# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
curl http://localhost:8000/api/v1/ai/stats

# –¢–µ—Å—Ç—ã
pytest tests/test_ai_core.py -v

# Linting
ruff check backend/service/ai_core.py
```

### Common issues

| –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ—à–µ–Ω–∏–µ |
|----------|---------|
| `KolibriAICore not found` | `pip install -r requirements.txt` |
| `asyncio error` | –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `asyncio.run()` –∏–ª–∏ `await` –≤ async –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ |
| `Signature mismatch` | –ü—Ä–æ–≤–µ—Ä—å—Ç–µ secret_key —Å–æ–≤–ø–∞–¥–∞–µ—Ç |
| `LLM not available` | –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ollama –∏–ª–∏ –æ—Ç–∫–ª—é—á–∏—Ç–µ `enable_llm=False` |

---

## üìû –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: [`KOLIBRI_AI_IMPLEMENTATION.md`](KOLIBRI_AI_IMPLEMENTATION.md)
- **–°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞**: [`KOLIBRI_AI_FINAL_STATUS.md`](KOLIBRI_AI_FINAL_STATUS.md)
- **–ú–∞–Ω–∏—Ñ–µ—Å—Ç**: [`projects/kolibri_ai_edge/AGI_MANIFESTO.md`](projects/kolibri_ai_edge/AGI_MANIFESTO.md)
- **API docs**: `http://localhost:8000/docs` (Swagger UI)

---

**–ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é! üöÄ**
