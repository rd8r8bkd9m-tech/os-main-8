#!/usr/bin/env python3
"""
Kolibri AI â€” Interactive Demo Script
Demonstrates the AI system functionality via HTTP API
"""

import asyncio
import json
import httpx
import sys

BASE_URL = "http://localhost:8000"

async def test_ai_reason():
    """Test single reasoning request"""
    print("\n" + "="*70)
    print("ğŸ§  TEST 1: Single AI Reasoning")
    print("="*70)
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        queries = [
            "What is photosynthesis?",
            "How does machine learning work?",
            "What is 2+2?",
        ]
        
        for query in queries:
            print(f"\nğŸ“ Query: {query}")
            try:
                response = await client.post(
                    f"{BASE_URL}/api/v1/ai/reason",
                    json={"prompt": query}
                )
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"âœ… Response: {data.get('response', 'N/A')[:100]}...")
                    print(f"   Confidence: {data.get('confidence', 0):.1%}")
                    print(f"   Energy: {data.get('energy_cost_j', 0):.3f}J")
                    print(f"   Mode: {data.get('mode', 'unknown')}")
                    print(f"   Verified: {data.get('verified', False)}")
                else:
                    print(f"âŒ Error: {response.status_code}")
            except Exception as e:
                print(f"âŒ Exception: {e}")

async def test_batch_reasoning():
    """Test batch reasoning"""
    print("\n" + "="*70)
    print("ğŸ”„ TEST 2: Batch Reasoning")
    print("="*70)
    
    queries = [
        "What is AI?",
        "Explain quantum computing",
        "How do neural networks work?",
        "What is blockchain?",
        "Define machine learning",
    ]
    
    print(f"\nğŸ“Š Processing {len(queries)} queries in parallel...")
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(
                f"{BASE_URL}/api/v1/ai/reason/batch",
                json={"queries": queries}
            )
            
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… Batch processed successfully")
                print(f"   Total energy: {data.get('total_energy_j', 0):.3f}J")
                print(f"   Total latency: {data.get('total_latency_ms', 0):.1f}ms")
                print(f"   Batch size: {data.get('batch_size', 0)}")
                
                for i, decision in enumerate(data.get('decisions', []), 1):
                    print(f"\n   {i}. Query: {decision.get('query', 'N/A')[:50]}...")
                    print(f"      Confidence: {decision.get('confidence', 0):.1%}")
                    print(f"      Verified: {decision.get('verified', False)}")
            else:
                print(f"âŒ Error: {response.status_code}")
        except Exception as e:
            print(f"âŒ Exception: {e}")

async def test_stats():
    """Get system statistics"""
    print("\n" + "="*70)
    print("ğŸ“Š TEST 3: System Statistics")
    print("="*70)
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            response = await client.get(f"{BASE_URL}/api/v1/ai/stats")
            
            if response.status_code == 200:
                data = response.json()
                print(f"\nâœ… System Statistics:")
                print(f"   Total queries: {data.get('total_queries', 0)}")
                print(f"   Total energy: {data.get('total_energy_j', 0):.3f}J")
                print(f"   Avg per query: {data.get('avg_energy_per_query_j', 0):.3f}J")
                print(f"   Mode: {data.get('mode', 'unknown')}")
            else:
                print(f"âŒ Error: {response.status_code}")
        except Exception as e:
            print(f"âŒ Exception: {e}")

async def test_api_docs():
    """Show API documentation link"""
    print("\n" + "="*70)
    print("ğŸ“š API Documentation")
    print("="*70)
    print(f"\nğŸŒ Interactive API docs available at:")
    print(f"   http://localhost:8000/docs (Swagger UI)")
    print(f"   http://localhost:8000/redoc (ReDoc)")

async def main():
    """Run all tests"""
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                   KOLIBRI AI SYSTEM DEMO                         â•‘")
    print("â•‘                  Interactive Testing Suite                       â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    print("\nâ³ Waiting for server to be ready...")
    await asyncio.sleep(2)
    
    try:
        # Check if server is up
        async with httpx.AsyncClient(timeout=5.0) as client:
            try:
                response = await client.get(f"{BASE_URL}/api/v1/ai/stats")
                if response.status_code != 200:
                    print("âš ï¸  Server may not be ready yet")
                    return
            except Exception as e:
                print(f"âŒ Cannot connect to server: {e}")
                print(f"\nğŸ’¡ Tip: Make sure server is running:")
                print(f"   uvicorn backend.service.main:app --reload")
                return
        
        # Run tests
        await test_ai_reason()
        await test_batch_reasoning()
        await test_stats()
        await test_api_docs()
        
        print("\n" + "="*70)
        print("âœ… Demo Complete!")
        print("="*70)
        print("\nğŸ“– For more information:")
        print("   â€¢ Quick Start: KOLIBRI_AI_QUICKSTART.md")
        print("   â€¢ Full Spec: KOLIBRI_AI_IMPLEMENTATION.md")
        print("   â€¢ Status: KOLIBRI_AI_FINAL_STATUS.md")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Demo interrupted by user")
        sys.exit(0)

if __name__ == "__main__":
    asyncio.run(main())
